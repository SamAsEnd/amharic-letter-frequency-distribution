\section{Limitations of the study}

The first limitations I was faced was the lack of a large dataset of processable Amharic text, Which took me more than half of my time doing this analysis. When some texts were found, most of them were just a scanned version of the printed book or newspaper which made it hard for processing.

The lack of publicly available (open source) optical character recognition(OCR) for the Amharic language made it hard to analyze the scanned version of the printed book or newspaper. If OCR was available it was possible to analyze additional datasets which were stored as an image.

One of the analyses I was planning to do was the root word (\foreignlanguage{ethiop}{serewa qAle}) frequency which will give a great insight into the most common words we use in the language. Analysing an Amharic word into their constituent morphemes (meaningful parts) is a challenging by itself and out of this paper scope. So I used 'HORNMORPHO 2.5'\cite{HornMorpho} python package developed by Michael Gasser of Indiana University, School of Informatics and Computing.  HORNMORPHO is a Python program that analyzes Amharic, Oromo, and Tigrinya words into their constituent morphemes (meaningful parts) and generates words, given a root or stem and a representation of the wordâ€™s grammatical structure. HORNMORPHO is very slow and requires a high computational capability to analyze millions of words. So, I have excluded root word frequency from this paper.

I also have faced another limitation when I conduct the word length frequency. I have stated in the methodology section, I have used 'pdftotext' conversion tool to convert the documents to a plain file. In some of the texts, I have noticed the tool was not recognizing the space between words and it was combined them into a single word. For example, I have found 50 character length word '\foreignlanguage{ethiop}{gamegAmibAlamuyAwo^cegArekamaqerabA^cawubafitebaqedemiyAsefalAgiwuhulu}' which is understandable and can be divided into a properly separated words '\foreignlanguage{ethiop}{gamegAmi bAlamuyAwo^ce gAre kamaqerabA^cawu bafite baqedemiyA sefalAgiwu hulu}' manually with ease but hard to automate and integrate into the analysis process. Thus I have removed the larger word length occurrences.

Lastly, I want to point out that more than 50 percent of the text I found was religiously or politically biased. Most of the available processable text out there is biased which made my trigram frequency to not look native. 